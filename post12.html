<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advisory Opinions: Episode 2 - Imagined Responses</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
   
    <header>
        <h1><em>Mind, Machine, and Will</em>: Imagined Responses</h1>
        <nav>
            <a href="index.html">Home</a>
        </nav>
    </header>
    <div class="disclaimer-box">
    <p><strong>Disclaimer:</strong> The following essay is a work of speculative fiction and parody. It is an imagined response, written in the style of the author named below, to the manuscript <em>Mind, Machine, and Will</em>. The views expressed herein are a simulation and <strong>do not represent the actual opinions of the author named below</strong>. Please read the full project description on the <a href="index.html">homepage</a> for more context.</p>
</div>
    <main>
        <article class="blog-post">
            <h2>Advisory Opinions: Episode 2</h2>
            <p class="meta">By David French and Sarah Isgur | August 8, 2025</p>
            <p><em>This is the second in a series of posts based on the entire Advisory Opinions Podcast. For a sample episode, link out to this url: <a href="https://www.youtube.com/watch?v=G-95Rgbu8kM">https://www.youtube.com/watch?v=G-95Rgbu8kM</a>. Info for this sample: Get Rid of the Autopen | w/ David French and Sarah Isgur. Advisory Opinions Podcast. 2.4K views. 10 days ago. Advisory Opinions.</em></p>
            <p>(Intro Music with an academic, slightly classical feel fades in and then fades out)</p>
            <p>Sarah Isgur: Welcome back to Advisory Opinions and our ongoing series on the manuscript Mind, Machine, and Will. I’m Sarah Isgur, here with David French.</p>
            <p>David French: It’s great to be back, Sarah.</p>
            <p>Sarah Isgur: Last week, we introduced the book’s central thesis: that our legal system is fundamentally broken because it rests on the impossible task of knowing what’s inside a person’s head—their "private mental states." The book argues we should replace that with a system based on observable, "public practices." David, you were intrigued. I was… let’s just say, deeply skeptical.</p>
            <p>David French: You used the word "horrified," I believe.</p>
            <p>Sarah Isgur: I believe I did. Because it felt like it was stripping the moral soul out of the law. But today, we’re moving from the abstract to the concrete. The authors argue that this philosophical shift isn’t just a theory; it’s already happening under duress in one specific area of law. I’ll start with the quote they use to frame this:</p>
            <p>(Reading from script) “Together, the Thaler rulings and the Copyright Office report function as a doctrinal laboratory testing the viability of mental-state–based authorship in the age of generative technology.”</p>
            <p>Sarah Isgur: I love this framing of a ‘doctrinal laboratory’ because it implies explosions and unforeseen consequences, which is exactly what we’re seeing with AI and copyright. So David, the easy case was Thaler v. Perlmutter. An AI created a piece of art, the human owner tried to copyright it, and the D.C. Circuit said no. The Copyright Act of 1976 implies a human author. Case closed, right? But the book says this was just kicking the can down the road.</p>
            <p>David French: It was. Because it answered the easy question—can a machine be an author?—but it completely ignored the hard one: how much human involvement is enough to make a human the author of a work created with AI? This is where the old framework completely breaks down. The law has historically relied on this fuzzy concept of "original intellectual conception"—an idea that comes directly from what the book calls a "private mental state." It’s about the spark of genius in the author’s mind. But how do you measure that spark when the process is a human typing a sentence into a machine that then generates a novel?</p>
            <p>Sarah Isgur: And that’s the problem. You can’t. You’re asking a federal judge, who probably still uses WordPerfect, to make a subjective, aesthetic judgment about the creative input of a prompt engineer. It’s an unworkable standard. It’s not a legal question; it’s a question for an art critic. And I fundamentally object to a legal system that requires judges to be art critics. The law should be objective, predictable. This feels like the opposite.</p>
            <p>David French: But this is where the manuscript’s central critique becomes so powerful. It argues that the standard was always unworkable. We were just able to maintain the illusion because the tools were simpler. This is from a section titled "The Human Authorship Requirement as Philosophical Error":</p>
            <p>(Reading from script) “The persistent requirement for a 'human touch' reflects a philosophical error: it locates the value and protectability of a work in what cannot be observed or adjudicated, rather than in the practices, standards, and outcomes of creative processes.”</p>
            <p>David French: That’s the core of it. The "philosophical error" isn't the rise of AI; it's the centuries-old belief that we can build a legal standard around an unobservable, un-adjudicable "inner spark." The authors are arguing that AI isn't breaking the law; it's just exposing how the law was already broken. It’s forcing us to abandon this romantic myth of the lone genius and move toward a more rigorous, procedural standard that is actually based on evidence.</p>
            <p>Sarah Isgur: I don't see it as a myth, David. I see it as the spirit of the law. The Copyright Clause was written to "promote the Progress of Science and useful Arts, by securing for limited Times to Authors and Inventors the exclusive Right to their respective Writings and Discoveries." That word, "Authors," has meaning. It implies a human soul, a human perspective, a human act of creation. What you’re calling a ‘philosophical error,’ I call the entire moral and philosophical underpinning of intellectual property. The idea isn't just to reward the labor of production; it's to reward the uniquely human act of creation. This "practice-based" model you’re describing feels like it reduces authorship to a technical, soulless process. It takes the author out of authorship.</p>
            <p>David French: I disagree. I think it makes it more rigorous by grounding it in the principles of American liberalism: public reason and verifiable evidence. Instead of a judge trying to mystically connect with the author's inner muse, we are asking them to do what judges are actually good at: analyzing a factual record according to a clear, public standard. It's a profoundly rule-of-law argument. It democratizes creativity by saying we will judge your work not by some inaccessible inner state, but by your observable participation in the creative process.</p>
            <p>(Transition Music)</p>
            <p>Sarah Isgur: Okay, so let's get practical. If we throw out the 'spark of genius' test, what do we replace it with? This is where the manuscript introduces a case called Bartz v. Anthropic. It’s a hypothetical case, but it’s based on real litigation happening right now. In this case, an AI company uses a massive dataset of copyrighted books to train its language model. The authors sue. The question is, is that fair use? The manuscript argues the court’s decision marks an "accidental breakthrough."</p>
            <p>(Reading from script) “This bifurcation constitutes an ‘accidental breakthrough’ because it delineates the boundaries for permissible AI development, affirming that the legality and provenance of training data now play a decisive role in the attribution of authorship and originality.”</p>
            <p>Sarah Isgur: I find this fascinating. The "breakthrough" isn't some grand philosophical declaration. It’s a gritty, practical, evidentiary question: did you steal the books you used to train your AI? Suddenly, the court doesn’t have to answer the impossible question of whether the AI is 'thinking' or 'creating.' It just has to answer a much simpler question: what is the provenance of the training data? That’s a question that can be answered through discovery. It turns this existential crisis into a mundane legal dispute, which, frankly, is a huge relief. It’s a way out of the philosophical trap.</p>
            <p>David French: It is a way out, but it's also much more than that. It’s the embodiment of the "practice-based" turn. The court is no longer looking at the output and trying to divine its creative essence. It’s looking at the input and the process. Was the practice of acquiring the data lawful? Was the practice of using the data transformative? This is a fundamental shift. It’s an objective, procedural inquiry. And it aligns perfectly with the core tenets of a liberal legal order. Justice shouldn't depend on a judge's subjective feelings about art; it should depend on the consistent application of public rules to verifiable facts.</p>
            <p>Sarah Isgur: But I think you're papering over how radical this really is. You're focusing on the "did you steal the data" part, which is easy. The harder part is the second half of that test: was the use "transformative"? That puts us right back in the subjective soup. The manuscript champions this new standard, and here’s the quote:</p>
            <p>(Reading from script) “The Bartz standard establishes that value creation—understood as public benefit and transformation—trumps the requirement of creative intention, providing a model that is both ethically justified and pragmatically robust.”</p>
            <p>Sarah Isgur: "Value creation." "Public benefit." David, who on earth is qualified to make that determination? We’re taking a difficult but at least theoretically contained question—what did the author intend?—and replacing it with a completely unbounded and political question: is this art good for society? That is a terrifying standard. It invites judges to become social engineers, rewarding art that aligns with their own view of the "public benefit" and punishing art that doesn’t. That’s not a legal standard; it’s a recipe for censorship.</p>
            <p>David French: I think you’re misinterpreting what "value creation" means in this context. It's not about a judge deciding if a painting is beautiful or if a novel has a good moral message. It's a term of art within fair use doctrine. The question is whether the new work transforms the original in such a way that it creates a new market, a new meaning, or a new purpose, rather than just superseding the original. It’s an economic and functional analysis, not an aesthetic one. It’s still a difficult inquiry, I grant you, but it’s one that courts have been doing for decades under fair use. All this does is clarify that this functional transformation is the central question, not the author’s private intention.</p>
            <p>Sarah Isgur: I just don’t buy that it can be separated from a judge’s own biases. If a work is a parody that viciously mocks a judge’s deeply held beliefs, are you telling me that judge will be able to objectively assess its "transformative value"? By getting rid of the author's intent as the anchor, you're setting the entire analysis adrift on a sea of subjectivity. You're replacing the spirit of the law—the protection of human creation—with a cold, utilitarian calculus that I think is deeply dangerous and, frankly, anti-humanist.</p>
            <p>David French: And I think clinging to the "spirit of the law" is a retreat from the rule of law. The spirit is unknowable. The process is knowable. A system of laws must be based on what is public and contestable. Insisting on a metaphysical "spark" is an invitation to arbitrary decision-making. Grounding the analysis in observable practice and procedure is the only way to ensure that the law is applied equally to all. It's the harder path, but it's the only one consistent with our legal tradition.</p>
            <p>(Transition Music)</p>
            <p>Sarah Isgur: So, David, as we wrap up this discussion on the ‘doctrinal laboratory’ of copyright, it seems we’ve hit the core of our disagreement. You see the book's argument as a logical, rigorous, and necessary evolution toward a more procedural, and therefore more just, legal system.</p>
            <p>David French: I see it as a framework that takes our liberal legal principles seriously. It demands that the law operate in the realm of public, verifiable evidence, not private, unknowable intuitions.</p>
            <p>Sarah Isgur: And I see it as a framework that, in its zeal for procedural purity, sacrifices the entire purpose of the law it’s meant to uphold. It throws the baby—the unique, invaluable spark of human authorship—out with the bathwater of metaphysical uncertainty. The authors’ final conclusion on this section is perhaps the most revealing.</p>
            <p>(Reading from script) “The chapter concludes that letting go of human exceptionalism in copyright is not a concession to technology, but a principled step toward a more inclusive, participatory, and pragmatic regime—one in which meaning, agency, and ownership are defined not by hidden mental states, but by open participation in the ever-evolving practice of creation.”</p>
            <p>David French: And I find that incredibly compelling. "Human exceptionalism" can be a form of mystification. This is a call for a more humble, more honest account of creativity—one that recognizes it as a social, collaborative practice, which it always has been. This isn't a demotion of humanity; it's a more accurate appraisal of it.</p>
            <p>Sarah Isgur: See, I read "letting go of human exceptionalism" and I get very nervous. Because the law, at its best, is about human exceptionalism. It's about recognizing the unique dignity and worth of the individual human person. A framework that starts by jettisoning that principle is starting from a very dangerous place. But if you think the debate over AI art is fraught with peril, what happens when this same logic gets applied to questions of life and liberty?</p>
            <p>David French: That is the question for next week.</p>
            <p>Sarah Isgur: That's right. Next week, we’re leaving the copyright lab and heading to the criminal court, where the manuscript argues that neuroscience is eroding the very concepts of blame and free will. The stakes are about to get a whole lot higher.</p>
            <p>(Outro Music Fades In)</p>
        </article>
    </main>
    <footer>
        <p><a href="index.html">Return to the full list of essays.</a></p>
    </footer>
</body>
</html>